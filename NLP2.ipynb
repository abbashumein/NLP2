{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "jE8GrsCpxZCM",
        "outputId": "17b2152e-1837-4870-e0c2-46f8a4278546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.0.post1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n",
            "Downloading gensim-4.3.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.16.1\n",
            "    Uninstalling scipy-1.16.1:\n",
            "      Successfully uninstalled scipy-1.16.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "scipy"
                ]
              },
              "id": "c7e03ae99d954cf4a115100106cc0890"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Given Amazon product reviews (text data), classify each review’s sentiment as positive, negative, or neutral based on its content. For example, a review saying “This phone is amazing!” should be classified as positive, while “Terrible quality, broke in a week” is negative."
      ],
      "metadata": {
        "id": "wyjJGQEbx_R6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "7qRbFcxyyMiT",
        "outputId": "d806dab3-eb4f-4826-be7a-8acc486807d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d103cc3c-df44-40b8-ba23-d1855d56d5d0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d103cc3c-df44-40b8-ba23-d1855d56d5d0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Amazon_Reviews.csv to Amazon_Reviews (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Try with error handling\n",
        "data = pd.read_csv(\"Amazon_Reviews.csv\", on_bad_lines=\"skip\", encoding=\"utf-8\", engine=\"python\")\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "isah4jOpz7J-",
        "outputId": "2f0c36ff-8e1a-4d2d-861c-17776e198d3c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Reviewer Name                     Profile Link Country Review Count  \\\n",
              "0        Eugene ath  /users/66e8185ff1598352d6b3701a      US     1 review   \n",
              "1  Daniel ohalloran  /users/5d75e460200c1f6a6373648c      GB    9 reviews   \n",
              "2          p fisher  /users/546cfcf1000064000197b88f      GB   90 reviews   \n",
              "3         Greg Dunn  /users/62c35cdbacc0ea0012ccaffa      AU    5 reviews   \n",
              "4     Sheila Hannah  /users/5ddbe429478d88251550610e      GB    8 reviews   \n",
              "\n",
              "                Review Date                  Rating  \\\n",
              "0  2024-09-16T13:44:26.000Z  Rated 1 out of 5 stars   \n",
              "1  2024-09-16T18:26:46.000Z  Rated 1 out of 5 stars   \n",
              "2  2024-09-16T21:47:39.000Z  Rated 1 out of 5 stars   \n",
              "3  2024-09-17T07:15:49.000Z  Rated 1 out of 5 stars   \n",
              "4  2024-09-16T18:37:17.000Z  Rated 1 out of 5 stars   \n",
              "\n",
              "                                      Review Title  \\\n",
              "0       A Store That Doesn't Want to Sell Anything   \n",
              "1           Had multiple orders one turned up and…   \n",
              "2                      I informed these reprobates   \n",
              "3  Advertise one price then increase it on website   \n",
              "4             If I could give a lower rate I would   \n",
              "\n",
              "                                         Review Text Date of Experience  \n",
              "0  I registered on the website, tried to order a ...          16-Sep-24  \n",
              "1  Had multiple orders one turned up and driver h...          16-Sep-24  \n",
              "2  I informed these reprobates that I WOULD NOT B...          16-Sep-24  \n",
              "3  I have bought from Amazon before and no proble...          17-Sep-24  \n",
              "4  If I could give a lower rate I would! I cancel...          16-Sep-24  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea3ec15e-22b7-4e81-a99e-8cd715fe26f6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Reviewer Name</th>\n",
              "      <th>Profile Link</th>\n",
              "      <th>Country</th>\n",
              "      <th>Review Count</th>\n",
              "      <th>Review Date</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Date of Experience</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eugene ath</td>\n",
              "      <td>/users/66e8185ff1598352d6b3701a</td>\n",
              "      <td>US</td>\n",
              "      <td>1 review</td>\n",
              "      <td>2024-09-16T13:44:26.000Z</td>\n",
              "      <td>Rated 1 out of 5 stars</td>\n",
              "      <td>A Store That Doesn't Want to Sell Anything</td>\n",
              "      <td>I registered on the website, tried to order a ...</td>\n",
              "      <td>16-Sep-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Daniel ohalloran</td>\n",
              "      <td>/users/5d75e460200c1f6a6373648c</td>\n",
              "      <td>GB</td>\n",
              "      <td>9 reviews</td>\n",
              "      <td>2024-09-16T18:26:46.000Z</td>\n",
              "      <td>Rated 1 out of 5 stars</td>\n",
              "      <td>Had multiple orders one turned up and…</td>\n",
              "      <td>Had multiple orders one turned up and driver h...</td>\n",
              "      <td>16-Sep-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p fisher</td>\n",
              "      <td>/users/546cfcf1000064000197b88f</td>\n",
              "      <td>GB</td>\n",
              "      <td>90 reviews</td>\n",
              "      <td>2024-09-16T21:47:39.000Z</td>\n",
              "      <td>Rated 1 out of 5 stars</td>\n",
              "      <td>I informed these reprobates</td>\n",
              "      <td>I informed these reprobates that I WOULD NOT B...</td>\n",
              "      <td>16-Sep-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Greg Dunn</td>\n",
              "      <td>/users/62c35cdbacc0ea0012ccaffa</td>\n",
              "      <td>AU</td>\n",
              "      <td>5 reviews</td>\n",
              "      <td>2024-09-17T07:15:49.000Z</td>\n",
              "      <td>Rated 1 out of 5 stars</td>\n",
              "      <td>Advertise one price then increase it on website</td>\n",
              "      <td>I have bought from Amazon before and no proble...</td>\n",
              "      <td>17-Sep-24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sheila Hannah</td>\n",
              "      <td>/users/5ddbe429478d88251550610e</td>\n",
              "      <td>GB</td>\n",
              "      <td>8 reviews</td>\n",
              "      <td>2024-09-16T18:37:17.000Z</td>\n",
              "      <td>Rated 1 out of 5 stars</td>\n",
              "      <td>If I could give a lower rate I would</td>\n",
              "      <td>If I could give a lower rate I would! I cancel...</td>\n",
              "      <td>16-Sep-24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea3ec15e-22b7-4e81-a99e-8cd715fe26f6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea3ec15e-22b7-4e81-a99e-8cd715fe26f6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea3ec15e-22b7-4e81-a99e-8cd715fe26f6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-621b9091-56a5-445b-836a-b99077930857\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-621b9091-56a5-445b-836a-b99077930857')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-621b9091-56a5-445b-836a-b99077930857 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 21214,\n  \"fields\": [\n    {\n      \"column\": \"Reviewer Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18531,\n        \"samples\": [\n          \"N Niertit\",\n          \"UDAYA YARI\",\n          \"Lisa Waterfield\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profile Link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21156,\n        \"samples\": [\n          \"/users/585458ba0000ff000a6294a5\",\n          \"/users/572fbe970000ff000a1e4748\",\n          \"/users/5bdf760b4de5666d3447e326\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Country\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 148,\n        \"samples\": [\n          \"LA\",\n          \"CV\",\n          \"IR\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review Count\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 177,\n        \"samples\": [\n          \"76 reviews\",\n          \"41 reviews\",\n          \"99 reviews\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 21054,\n        \"samples\": [\n          \"2019-11-20T14:27:48.000Z\",\n          \"2011-12-28T09:32:18.000Z\",\n          \"2021-06-04T01:47:25.000Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Rated 5 out of 5 stars\",\n          \"Rated 3 out of 5 stars\",\n          \"Rated 2 out of 5 stars\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19277,\n        \"samples\": [\n          \"This company is nothing but trash\",\n          \"Don't give a damm about refunding their\\u2026\",\n          \"Amazon gets worse everyday\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Review Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20407,\n        \"samples\": [\n          \"I am a consistent Amazon shopper, it has so many things i want or need and for the most part receive it in less than 7 days. I've purchased large items such as furniture to small things like vitamins and i've never gotten ripped off\",\n          \"Great website full of variety, choice and deals. Really simple checkout process.\",\n          \"I cannot thank Amazon enough for providing a consistent high quality of deliveries. My estate has been having road works etc and road closures yet the Amazon driver delivered both packages on time and so good. My mum will be very pleased with her new bag.Date of experience: July 07, 2023\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Date of Experience\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3640,\n        \"samples\": [\n          \"22-Oct-23\",\n          \"3-Oct-15\",\n          \"29-Aug-19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.info(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4u3XqYf0nfT",
        "outputId": "2134643d-acbe-47f9-d705-77edaebf8feb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21214 entries, 0 to 21213\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   Reviewer Name       21214 non-null  object\n",
            " 1   Profile Link        21163 non-null  object\n",
            " 2   Country             21054 non-null  object\n",
            " 3   Review Count        21055 non-null  object\n",
            " 4   Review Date         21055 non-null  object\n",
            " 5   Rating              21055 non-null  object\n",
            " 6   Review Title        21055 non-null  object\n",
            " 7   Review Text         21055 non-null  object\n",
            " 8   Date of Experience  20947 non-null  object\n",
            "dtypes: object(9)\n",
            "memory usage: 1.5+ MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data frame, containing 21,214 entries across 9 columns, consists entirely of object data types and has missing values in several columns"
      ],
      "metadata": {
        "id": "SA0jzXoZ1jy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_count = len(data)\n",
        "print(f\"Total Review Count: {review_count}\")"
      ],
      "metadata": {
        "id": "-l0GldnN3MZk",
        "outputId": "ae34ab17-74b3-49a4-aa56-765eb538e551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Review Count: 21214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Review Count'] = data['Review Count'].str.replace(' reviews', '', regex=False).str.replace(' review', '', regex=False).astype(float).fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "LVGpXaedMiuK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Review Count'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR4THtd9RRyo",
        "outputId": "26ff57b3-1884-4b3e-a940-9d185185b4e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0     1\n",
            "1     9\n",
            "2    90\n",
            "3     5\n",
            "4     8\n",
            "5     4\n",
            "6    30\n",
            "7     2\n",
            "8     1\n",
            "9     3\n",
            "Name: Review Count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['Review Date'] = pd.to_datetime(data['Review Date'], errors='coerce')\n",
        "data['Date of Experience'] = pd.to_datetime(data['Date of Experience'], errors='coerce')\n",
        "\n",
        "# Now you can check how many values were successfully converted\n",
        "print(f\"Number of valid 'Review Date' entries: {data['Review Date'].notna().sum()}\")\n",
        "print(f\"Number of valid 'Date of Experience' entries: {data['Date of Experience'].notna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASLIL0WSNRtF",
        "outputId": "cf7152b7-a73e-44e1-e75c-5a4a2238630e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of valid 'Review Date' entries: 21055\n",
            "Number of valid 'Date of Experience' entries: 20947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1536767063.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  data['Date of Experience'] = pd.to_datetime(data['Date of Experience'], errors='coerce')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Review Date'].head(10))\n",
        "print(data['Date of Experience'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tRq7TNdSjKB",
        "outputId": "c98c7e86-b7cd-44a9-9837-1aa71d514d3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   2024-09-16 13:44:26+00:00\n",
            "1   2024-09-16 18:26:46+00:00\n",
            "2   2024-09-16 21:47:39+00:00\n",
            "3   2024-09-17 07:15:49+00:00\n",
            "4   2024-09-16 18:37:17+00:00\n",
            "5   2024-09-17 10:07:38+00:00\n",
            "6   2024-09-16 23:43:32+00:00\n",
            "7   2024-09-15 18:07:45+00:00\n",
            "8   2024-09-17 13:00:12+00:00\n",
            "9   2024-09-16 21:04:07+00:00\n",
            "Name: Review Date, dtype: datetime64[ns, UTC]\n",
            "0   2024-09-16\n",
            "1   2024-09-16\n",
            "2   2024-09-16\n",
            "3   2024-09-17\n",
            "4   2024-09-16\n",
            "5   2024-08-16\n",
            "6   2024-09-16\n",
            "7   2024-09-15\n",
            "8   2024-09-17\n",
            "9   2024-09-13\n",
            "Name: Date of Experience, dtype: datetime64[ns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose columns: 'reviewText' and 'sentiment' (adjust as per dataset)\n",
        "data = data[['Review Text', 'Rating']]\n",
        "\n",
        "print(data.shape)\n",
        "print(data.head(5))"
      ],
      "metadata": {
        "id": "JWPprm-LWKU5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3557535-53d2-42ac-8993-263878324fd9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21214, 2)\n",
            "                                         Review Text                  Rating\n",
            "0  I registered on the website, tried to order a ...  Rated 1 out of 5 stars\n",
            "1  Had multiple orders one turned up and driver h...  Rated 1 out of 5 stars\n",
            "2  I informed these reprobates that I WOULD NOT B...  Rated 1 out of 5 stars\n",
            "3  I have bought from Amazon before and no proble...  Rated 1 out of 5 stars\n",
            "4  If I could give a lower rate I would! I cancel...  Rated 1 out of 5 stars\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Function to extract rating number from \"Rated X out of 5 stars\"\n",
        "def extract_rating(text):\n",
        "    if pd.isna(text):  # handle NaN\n",
        "        return None\n",
        "    match = re.search(r'(\\d) out of 5', str(text))\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "# Apply extraction\n",
        "data['Rating_num'] = data['Rating'].apply(extract_rating)\n",
        "\n",
        "# Now create sentiment labels\n",
        "def label_sentiment(rating):\n",
        "    if pd.isna(rating):\n",
        "        return None\n",
        "    if rating <= 2:\n",
        "        return \"negative\"\n",
        "    elif rating == 3:\n",
        "        return \"neutral\"\n",
        "    else:\n",
        "        return \"positive\"\n",
        "\n",
        "data['Sentiment'] = data['Rating_num'].apply(label_sentiment)\n",
        "\n",
        "# Check results\n",
        "print(data[['Rating', 'Rating_num', 'Sentiment']].head(10))\n",
        "print(data['Sentiment'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjbtr1XZZ6r3",
        "outputId": "f597cac7-62d4-4c82-f6c8-250a68839cdf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Rating  Rating_num Sentiment\n",
            "0  Rated 1 out of 5 stars         1.0  negative\n",
            "1  Rated 1 out of 5 stars         1.0  negative\n",
            "2  Rated 1 out of 5 stars         1.0  negative\n",
            "3  Rated 1 out of 5 stars         1.0  negative\n",
            "4  Rated 1 out of 5 stars         1.0  negative\n",
            "5  Rated 1 out of 5 stars         1.0  negative\n",
            "6  Rated 1 out of 5 stars         1.0  negative\n",
            "7  Rated 5 out of 5 stars         5.0  positive\n",
            "8  Rated 1 out of 5 stars         1.0  negative\n",
            "9  Rated 5 out of 5 stars         5.0  positive\n",
            "Sentiment\n",
            "negative    14350\n",
            "positive     5820\n",
            "neutral       885\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Rating'].head(10))\n",
        "print(data['Rating_num'].head(10))\n",
        "print(data['Sentiment'].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRpjoCwZZ80E",
        "outputId": "5c2c33cb-5710-4bfc-b04c-458a55935d46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    Rated 1 out of 5 stars\n",
            "1    Rated 1 out of 5 stars\n",
            "2    Rated 1 out of 5 stars\n",
            "3    Rated 1 out of 5 stars\n",
            "4    Rated 1 out of 5 stars\n",
            "5    Rated 1 out of 5 stars\n",
            "6    Rated 1 out of 5 stars\n",
            "7    Rated 5 out of 5 stars\n",
            "8    Rated 1 out of 5 stars\n",
            "9    Rated 5 out of 5 stars\n",
            "Name: Rating, dtype: object\n",
            "0    1.0\n",
            "1    1.0\n",
            "2    1.0\n",
            "3    1.0\n",
            "4    1.0\n",
            "5    1.0\n",
            "6    1.0\n",
            "7    5.0\n",
            "8    1.0\n",
            "9    5.0\n",
            "Name: Rating_num, dtype: float64\n",
            "0    negative\n",
            "1    negative\n",
            "2    negative\n",
            "3    negative\n",
            "4    negative\n",
            "5    negative\n",
            "6    negative\n",
            "7    positive\n",
            "8    negative\n",
            "9    positive\n",
            "Name: Sentiment, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert Rating_num to nullable integer\n",
        "data['Rating_num'] = pd.to_numeric(data['Rating_num'], errors='coerce')\n",
        "data['Rating_num'] = data['Rating_num'].astype('Int64')  # Nullable integer\n",
        "\n",
        "# Convert Sentiment to categorical (more efficient)\n",
        "data['Sentiment'] = data['Sentiment'].astype('category')\n",
        "\n",
        "# Check the results\n",
        "print(data.info())\n",
        "print(data['Rating_num'].dtype)  # Should show Int64\n",
        "print(data['Sentiment'].dtype)   # Should show category"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjrTgRJedue-",
        "outputId": "7539e4dd-3dca-4fee-c5b7-ea22e974ca51"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21214 entries, 0 to 21213\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   Review Text  21055 non-null  object  \n",
            " 1   Rating       21055 non-null  object  \n",
            " 2   Rating_num   21055 non-null  Int64   \n",
            " 3   Sentiment    21055 non-null  category\n",
            "dtypes: Int64(1), category(1), object(2)\n",
            "memory usage: 538.9+ KB\n",
            "None\n",
            "Int64\n",
            "category\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing ratings before conversion\n",
        "data_clean = data.dropna(subset=['Rating_num', 'Sentiment'])\n",
        "\n",
        "# Now convert to proper types\n",
        "data_clean['Rating_num'] = data_clean['Rating_num'].astype('int64')\n",
        "data_clean['Sentiment'] = data_clean['Sentiment'].astype('category')\n",
        "\n",
        "print(data_clean.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO5WIP8dedcs",
        "outputId": "011441e2-91b5-4363-8675-2ecb75441f06"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 21055 entries, 0 to 21213\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   Review Text  21055 non-null  object  \n",
            " 1   Rating       21055 non-null  object  \n",
            " 2   Rating_num   21055 non-null  int64   \n",
            " 3   Sentiment    21055 non-null  category\n",
            "dtypes: category(1), int64(1), object(2)\n",
            "memory usage: 678.7+ KB\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2431889522.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_clean['Rating_num'] = data_clean['Rating_num'].astype('int64')\n",
            "/tmp/ipython-input-2431889522.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_clean['Sentiment'] = data_clean['Sentiment'].astype('category')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check what's actually being extracted\n",
        "print(\"Sample Rating values:\")\n",
        "print(data['Rating'].head(20))\n",
        "print(\"\\nCorresponding Rating_num values:\")\n",
        "print(data['Rating_num'].head(20))\n",
        "print(\"\\nUnique Rating formats:\")\n",
        "print(data['Rating'].value_counts().head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwmtEZZqgsJn",
        "outputId": "ec317763-4053-48ab-cb41-b70d0bf0c903"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Rating values:\n",
            "0     Rated 1 out of 5 stars\n",
            "1     Rated 1 out of 5 stars\n",
            "2     Rated 1 out of 5 stars\n",
            "3     Rated 1 out of 5 stars\n",
            "4     Rated 1 out of 5 stars\n",
            "5     Rated 1 out of 5 stars\n",
            "6     Rated 1 out of 5 stars\n",
            "7     Rated 5 out of 5 stars\n",
            "8     Rated 1 out of 5 stars\n",
            "9     Rated 5 out of 5 stars\n",
            "10    Rated 5 out of 5 stars\n",
            "11    Rated 1 out of 5 stars\n",
            "12    Rated 2 out of 5 stars\n",
            "13    Rated 1 out of 5 stars\n",
            "14    Rated 1 out of 5 stars\n",
            "15    Rated 1 out of 5 stars\n",
            "16    Rated 1 out of 5 stars\n",
            "17    Rated 1 out of 5 stars\n",
            "18    Rated 1 out of 5 stars\n",
            "19    Rated 2 out of 5 stars\n",
            "Name: Rating, dtype: object\n",
            "\n",
            "Corresponding Rating_num values:\n",
            "0     1\n",
            "1     1\n",
            "2     1\n",
            "3     1\n",
            "4     1\n",
            "5     1\n",
            "6     1\n",
            "7     5\n",
            "8     1\n",
            "9     5\n",
            "10    5\n",
            "11    1\n",
            "12    2\n",
            "13    1\n",
            "14    1\n",
            "15    1\n",
            "16    1\n",
            "17    1\n",
            "18    1\n",
            "19    2\n",
            "Name: Rating_num, dtype: Int64\n",
            "\n",
            "Unique Rating formats:\n",
            "Rating\n",
            "Rated 1 out of 5 stars    13123\n",
            "Rated 5 out of 5 stars     4528\n",
            "Rated 4 out of 5 stars     1292\n",
            "Rated 2 out of 5 stars     1227\n",
            "Rated 3 out of 5 stars      885\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(data['Rating'].unique()[:10])  # Show first 10 unique values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf8YtVr7gwZ5",
        "outputId": "0d8a4038-cd25-4ae7-fe69-120d5b563828"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Rated 1 out of 5 stars' 'Rated 5 out of 5 stars'\n",
            " 'Rated 2 out of 5 stars' 'Rated 4 out of 5 stars'\n",
            " 'Rated 3 out of 5 stars' nan]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"None values in Rating_num: {data['Rating_num'].isna().sum()}\")\n",
        "print(f\"None values in Sentiment: {data['Sentiment'].isna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoj4lqlkg2k2",
        "outputId": "729696ea-b1e4-4da5-f6bc-ee1279d6fb26"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None values in Rating_num: 159\n",
            "None values in Sentiment: 159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your regex on sample data\n",
        "test_ratings = data['Rating'].dropna().head(10)\n",
        "for rating in test_ratings:\n",
        "    match = re.search(r'(\\d) out of 5', str(rating))\n",
        "    print(f\"'{rating}' → {match.group(1) if match else 'No match'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSMpAnldg4wp",
        "outputId": "0f49719c-3d76-4a97-8be0-caf44d1ea1eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 5 out of 5 stars' → 5\n",
            "'Rated 1 out of 5 stars' → 1\n",
            "'Rated 5 out of 5 stars' → 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_rating_improved(text):\n",
        "    if pd.isna(text):\n",
        "        return None\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Try multiple patterns\n",
        "    patterns = [\n",
        "        r'(\\d)(?:\\.\\d)?\\s*out of 5',  # \"4 out of 5\" or \"4.5 out of 5\"\n",
        "        r'rated\\s+(\\d)',              # \"Rated 4\"\n",
        "        r'^(\\d)(?:\\.\\d)?$',           # Just \"4\" or \"4.5\"\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        match = re.search(pattern, text)\n",
        "        if match:\n",
        "            return float(match.group(1))\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "3oB_ueU8hA1X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many extractions failed\n",
        "print(\"Extraction success rate:\")\n",
        "print(f\"Total rows: {len(data)}\")\n",
        "print(f\"Successful extractions: {data['Rating_num'].notna().sum()}\")\n",
        "print(f\"Failed extractions: {data['Rating_num'].isna().sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqLDA67JhG9L",
        "outputId": "2c33ca3b-a674-4505-e820-99b5694d7849"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction success rate:\n",
            "Total rows: 21214\n",
            "Successful extractions: 21055\n",
            "Failed extractions: 159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Improve extraction\n",
        "data['Rating_num'] = data['Rating'].apply(extract_rating_improved)\n",
        "\n",
        "# 2. Convert to proper types\n",
        "data['Rating_num'] = pd.to_numeric(data['Rating_num'], errors='coerce').astype('Int64')\n",
        "data['Sentiment'] = data['Sentiment'].astype('category')\n",
        "\n",
        "# 3. Clean data (remove failed extractions)\n",
        "data_clean = data.dropna(subset=['Rating_num', 'Sentiment']).copy()\n",
        "\n",
        "# 4. Verify\n",
        "print(data_clean.info())\n",
        "print(f\"Final dataset size: {len(data_clean)} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BId2jbO9hLqW",
        "outputId": "ea84523a-603f-4cc7-acb0-0ae80fe51e6e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 21055 entries, 0 to 21213\n",
            "Data columns (total 4 columns):\n",
            " #   Column       Non-Null Count  Dtype   \n",
            "---  ------       --------------  -----   \n",
            " 0   Review Text  21055 non-null  object  \n",
            " 1   Rating       21055 non-null  object  \n",
            " 2   Rating_num   21055 non-null  Int64   \n",
            " 3   Sentiment    21055 non-null  category\n",
            "dtypes: Int64(1), category(1), object(2)\n",
            "memory usage: 699.2+ KB\n",
            "None\n",
            "Final dataset size: 21055 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the class distribution\n",
        "print(\"Sentiment Distribution:\")\n",
        "print(data_clean['Sentiment'].value_counts())\n",
        "print(\"\\nPercentage Distribution:\")\n",
        "print(data_clean['Sentiment'].value_counts(normalize=True) * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZBfSG3-haWJ",
        "outputId": "9a9a6fde-9f53-4682-97f7-b1cf71b51129"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Distribution:\n",
            "Sentiment\n",
            "negative    14350\n",
            "positive     5820\n",
            "neutral       885\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentage Distribution:\n",
            "Sentiment\n",
            "negative    68.154833\n",
            "positive    27.641890\n",
            "neutral      4.203277\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Rating distribution\n",
        "print(\"Rating Distribution:\")\n",
        "print(data_clean['Rating_num'].value_counts().sort_index())\n",
        "\n",
        "# Sample some reviews by sentiment\n",
        "print(\"\\nSample Negative Reviews:\")\n",
        "print(data_clean[data_clean['Sentiment'] == 'negative']['Review Text'].head(3).values)\n",
        "\n",
        "print(\"\\nSample Positive Reviews:\")\n",
        "print(data_clean[data_clean['Sentiment'] == 'positive']['Review Text'].head(3).values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqLOc8UhhdF6",
        "outputId": "4faa7a5d-47c8-4ddd-ed34-403d41945049"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rating Distribution:\n",
            "Rating_num\n",
            "1    13123\n",
            "2     1227\n",
            "3      885\n",
            "4     1292\n",
            "5     4528\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "Sample Negative Reviews:\n",
            "[\"I registered on the website, tried to order a laptop, entered all the details, but instead of charging me and sending the product, they froze my account, demanding various verification documents. I sent them over. They said they would review them within 24 hours. In reality, it's been a week, and no one can help or give any (truthful) estimate of when it will be resolved; they just tell me to 'wait.' I've never seen such a horrible marketplace in my life. I hope those who came up with this can't buy food in a store, receiving a 'document review request' that takes forever to process.\"\n",
            " \"Had multiple orders one turned up and driver had to phone as no door number on packaging, then waited all day for second package to get a message saying couldn't deliver as no number on packaging, 12 hours waiting in now don't even know when I'm getting delivery. Terrible will never use again\"\n",
            " 'I informed these reprobates that I WOULD NOT BE IN as I was going to visit a sick relative, they told me they were going to send a OTP, I told them I could not receive it as I was travelling a long way on the underground, their reply was don’t worry we can text. I pointed out I can’t receive texts EITHER!!They said parcel was on its way so couldn’t stop it. I pointed out I WOULD NOT WANT IT as, I had PERMANENTLY CLOSED my account!The driver came whilst I was out and failed to even follow my settings info that said to deliver to a specific neighbour if I was out, since then my account has now been deleted']\n",
            "\n",
            "Sample Positive Reviews:\n",
            "['I love amazon! I use it for half my shopping. The prime membership is worth it as you can receive free 2-day shipping on most purchases. The online store also has almost anything you can think of ranging from toiletries, clothes, to electronics and furniture!'\n",
            " 'I had a great experience with their customer service. They delivered my order to wrong address but didnt give me hassle of finding the item. Instead they said they will take care of it and replaced my order.'\n",
            " 'Every time there is a problem, they fix it. I have no idea why Amazon is so poorly rated here, because they provide incredible customer service and support.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"Clean and preprocess review text\"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # Remove URLs, mentions, hashtags\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "    # Remove special characters and digits\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "data_clean['Clean_Review'] = data_clean['Review Text'].apply(clean_text)\n",
        "\n",
        "# Remove empty reviews\n",
        "data_clean = data_clean[data_clean['Clean_Review'].str.len() > 10].copy()\n",
        "\n",
        "print(f\"After text cleaning: {len(data_clean)} rows\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7TI25IFhdCB",
        "outputId": "fb5ec6ec-70ee-4227-8f0e-2d704e24049d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After text cleaning: 21047 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Prepare features and target (this step was missing!)\n",
        "X = data_clean['Clean_Review']  # Your cleaned text\n",
        "y = data_clean['Sentiment']     # Your sentiment labels\n",
        "\n",
        "# Create train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y  # Keep same class distribution\n",
        ")\n",
        "\n",
        "print(f\"Training set: {len(X_train)} samples\")\n",
        "print(f\"Test set: {len(X_test)} samples\")\n",
        "print(f\"\\nOriginal training distribution:\")\n",
        "print(y_train.value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eS9Ey6MiiW8",
        "outputId": "567e091b-6e56-46f2-a3fd-315e6428e60e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: 16837 samples\n",
            "Test set: 4210 samples\n",
            "\n",
            "Original training distribution:\n",
            "Sentiment\n",
            "negative    0.681832\n",
            "positive    0.276118\n",
            "neutral     0.042050\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd\n",
        "\n",
        "print(\"🔄 Applying SMOTE to balance classes...\")\n",
        "\n",
        "# Vectorize text for SMOTE (it needs numerical features)\n",
        "tfidf_temp = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "X_tfidf_temp = tfidf_temp.fit_transform(X_train)\n",
        "\n",
        "print(f\"TF-IDF shape before SMOTE: {X_tfidf_temp.shape}\")\n",
        "print(f\"Class distribution before SMOTE:\")\n",
        "print(y_train.value_counts())\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(X_tfidf_temp, y_train)\n",
        "\n",
        "print(f\"\\nTF-IDF shape after SMOTE: {X_balanced.shape}\")\n",
        "print(\"After SMOTE balancing:\")\n",
        "print(pd.Series(y_balanced).value_counts())\n",
        "print(\"\\nPercentage distribution:\")\n",
        "print(pd.Series(y_balanced).value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTAIuNwpiQyY",
        "outputId": "41091dab-8668-41aa-ef26-223dd7569014"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Applying SMOTE to balance classes...\n",
            "TF-IDF shape before SMOTE: (16837, 1000)\n",
            "Class distribution before SMOTE:\n",
            "Sentiment\n",
            "negative    11480\n",
            "positive     4649\n",
            "neutral       708\n",
            "Name: count, dtype: int64\n",
            "\n",
            "TF-IDF shape after SMOTE: (34440, 1000)\n",
            "After SMOTE balancing:\n",
            "Sentiment\n",
            "negative    11480\n",
            "neutral     11480\n",
            "positive    11480\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Percentage distribution:\n",
            "Sentiment\n",
            "negative    0.333333\n",
            "neutral     0.333333\n",
            "positive    0.333333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Traditional (what you're comparing against)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "bow_model = CountVectorizer()  # One-hot encoding approach\n",
        "\n",
        "# Modern approach (what you're implementing)\n",
        "from gensim.models import Word2Vec\n",
        "w2v_model = Word2Vec()  # Distributed word representations"
      ],
      "metadata": {
        "id": "7jIdXgArl1Y3"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train on your balanced data\n",
        "sentences = [text.split() for text in X_train]  # Tokenize\n",
        "w2v_model = Word2Vec(\n",
        "    sentences=sentences,\n",
        "    vector_size=100,    # Manning discusses dimensionality\n",
        "    window=5,           # Context window (key Lecture 2 concept)\n",
        "    sg=0,               # CBOW vs Skip-gram\n",
        "    negative=5          # Negative sampling (Manning explains this)\n",
        ")\n",
        "\n",
        "# Test semantic relationships (Manning's favorite demo)\n",
        "similar_words = w2v_model.wv.most_similar('good', topn=5)\n",
        "print(f\"Words similar to 'good': {similar_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RMiGcOIl3sH",
        "outputId": "8bf52cb2-a7d0-4501-c796-eed83c442e4c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'good': [('great', 0.8649375438690186), ('convenient', 0.718320906162262), ('excellent', 0.6967635750770569), ('nice', 0.6855817437171936), ('bad', 0.685529887676239)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similar_words = w2v_model.wv.most_similar('truth', topn=5)\n",
        "print(f\"Words similar to 'truth': {similar_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTbyWXXem_4Q",
        "outputId": "4a7c0625-3cf5-4b29-c5d9-93d36b4e9418"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to 'truth': [('word', 0.6978323459625244), ('infringement', 0.6464583277702332), ('jobs', 0.6449962258338928), ('script', 0.6355670690536499), ('america', 0.6323620676994324)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================\n",
        "# Imports\n",
        "# =============================\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from gensim.models import Word2Vec\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# =============================\n",
        "# Sentiment Analyzer Class\n",
        "# =============================\n",
        "class SentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.tfidf_model = None\n",
        "        self.w2v_model = None\n",
        "        self.w2v_classifier = None\n",
        "        self.label_encoder = None\n",
        "\n",
        "    def train(self, X_train, y_train):\n",
        "        # Encode labels\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        y_encoded = self.label_encoder.fit_transform(y_train)\n",
        "\n",
        "        # TF-IDF\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(max_features=5000)\n",
        "        X_tfidf = self.tfidf_vectorizer.fit_transform(X_train)\n",
        "        self.tfidf_model = LogisticRegression(max_iter=500)\n",
        "        self.tfidf_model.fit(X_tfidf, y_encoded)\n",
        "\n",
        "        # Word2Vec\n",
        "        tokenized = [x.split() for x in X_train]\n",
        "        self.w2v_model = Word2Vec(sentences=tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "        X_w2v = np.array([np.mean([self.w2v_model.wv[w] for w in words if w in self.w2v_model.wv] or\n",
        "                                  [np.zeros(100)], axis=0) for words in tokenized])\n",
        "        self.w2v_classifier = LogisticRegression(max_iter=500)\n",
        "        self.w2v_classifier.fit(X_w2v, y_encoded)\n",
        "\n",
        "    def predict_tfidf(self, text):\n",
        "        vec = self.tfidf_vectorizer.transform([text])\n",
        "        probs = self.tfidf_model.predict_proba(vec)[0]\n",
        "        idx = np.argmax(probs)\n",
        "        return self.label_encoder.classes_[idx], dict(zip(self.label_encoder.classes_, probs))\n",
        "\n",
        "    def predict_w2v(self, text):\n",
        "        words = text.split()\n",
        "        vec = np.mean([self.w2v_model.wv[w] for w in words if w in self.w2v_model.wv] or\n",
        "                      [np.zeros(100)], axis=0).reshape(1, -1)\n",
        "        probs = self.w2v_classifier.predict_proba(vec)[0]\n",
        "        idx = np.argmax(probs)\n",
        "        return self.label_encoder.classes_[idx], dict(zip(self.label_encoder.classes_, probs))\n",
        "\n",
        "# =============================\n",
        "# Neural Network (Lecture 3)\n",
        "# =============================\n",
        "class SentimentMLP(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(SentimentMLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        return self.fc2(x)\n",
        "\n",
        "# Train simple NN on same data\n",
        "def train_neural(X_train, y_train, w2v_model, label_encoder, epochs=30):\n",
        "    # Convert training sentences to Word2Vec average vectors\n",
        "    X_train_vectors = np.array([\n",
        "        np.mean([w2v_model.wv[w] for w in x.split() if w in w2v_model.wv] or\n",
        "                [np.zeros(100)], axis=0) for x in X_train\n",
        "    ])\n",
        "    y_encoded = label_encoder.transform(y_train)\n",
        "\n",
        "    # Convert to tensors\n",
        "    X_tensor = torch.tensor(X_train_vectors, dtype=torch.float32)\n",
        "    y_tensor = torch.tensor(y_encoded, dtype=torch.long)\n",
        "\n",
        "    # Initialize model with correct input size\n",
        "    #print(\"\\n🧠 Step 4: Initializing Neural Network...\")\n",
        "    model = SentimentMLP(\n",
        "        input_dim=X_train_vectors.shape[1],     # ✅ FIXED\n",
        "        hidden_dim=128,\n",
        "        output_dim=len(label_encoder.classes_)\n",
        "    )\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Training loop\n",
        "    for _ in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        out = model(X_tensor)\n",
        "        loss = F.cross_entropy(out, y_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_neural(text, model, w2v_model, label_encoder):\n",
        "    words = text.split()\n",
        "    vec = np.mean([w2v_model.wv[w] for w in words if w in w2v_model.wv] or\n",
        "                  [np.zeros(100)], axis=0)\n",
        "    vec_tensor = torch.tensor(vec, dtype=torch.float32).unsqueeze(0)\n",
        "    probs = F.softmax(model(vec_tensor), dim=1).detach().numpy()[0]\n",
        "    idx = np.argmax(probs)\n",
        "    return label_encoder.classes_[idx], dict(zip(label_encoder.classes_, probs))\n",
        "\n",
        "# =============================\n",
        "# Training Data\n",
        "# =============================\n",
        "X_train = [\n",
        "    \"I love this phone, it is fantastic!\",\n",
        "    \"Terrible product, complete waste of money.\",\n",
        "    \"It’s okay, not too bad but not great either.\",\n",
        "    \"Amazing quality, I am very happy with it.\",\n",
        "    \"Worst purchase ever, I hate it.\"\n",
        "]\n",
        "y_train = [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\"]\n",
        "\n",
        "# =============================\n",
        "# Train Analyzer (TF-IDF + W2V)\n",
        "# =============================\n",
        "analyzer = SentimentAnalyzer()\n",
        "analyzer.train(X_train, y_train)\n",
        "\n",
        "# Save global Word2Vec and label encoder for NN\n",
        "w2v_model = analyzer.w2v_model\n",
        "label_encoder = analyzer.label_encoder\n",
        "\n",
        "# Train NN\n",
        "# Train NN\n",
        "neural_model = train_neural(X_train, y_train, w2v_model, label_encoder)\n",
        "\n",
        "# =============================\n",
        "# Gradio Interface\n",
        "# =============================\n",
        "def analyze(text):\n",
        "    tfidf_pred, tfidf_probs = analyzer.predict_tfidf(text)\n",
        "    w2v_pred, w2v_probs = analyzer.predict_w2v(text)\n",
        "    nn_pred, nn_probs = predict_neural(text, neural_model, w2v_model, label_encoder)\n",
        "\n",
        "    return (\n",
        "        f\"TF-IDF Prediction: {tfidf_pred}\\n\\nProbabilities: {tfidf_probs}\",\n",
        "        f\"Word2Vec Prediction: {w2v_pred}\\n\\nProbabilities: {w2v_probs}\",\n",
        "        f\"Neural Network Prediction: {nn_pred}\\n\\nProbabilities: {nn_probs}\"\n",
        "    )\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=analyze,\n",
        "    inputs=gr.Textbox(lines=2, placeholder=\"Enter a review...\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"TF-IDF Result\"),\n",
        "        gr.Textbox(label=\"Word2Vec Result\"),\n",
        "        gr.Textbox(label=\"Neural Network Result\")\n",
        "    ],\n",
        "    title=\"📊 Sentiment Analyzer (TF-IDF vs Word2Vec vs Neural Net)\"\n",
        ")"
      ],
      "metadata": {
        "id": "nyoyJo63oEfo"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and initialize\n",
        "#neural_model, vectorizer, label_encoder = run_cs224n_neural_sentiment()\n",
        "\n",
        "# Now test examples\n",
        "#test_neural_model(neural_model, vectorizer, label_encoder,\n",
        "                 #\"This product is absolutely amazing! Love it!\")\n",
        "\n",
        "#test_neural_model(neural_model, vectorizer, label_encoder,\n",
        "                # \"Terrible quality, complete waste of money!\")\n",
        "\n",
        "#test_neural_model(neural_model, vectorizer, label_encoder,\n",
        "                 #\"The product is okay, nothing special.\")\n",
        "\n",
        "#test_neural_model(neural_model, vectorizer, label_encoder,\n",
        "                 #\"Not bad at all, actually quite good!\")"
      ],
      "metadata": {
        "id": "runIcfXboYp1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "class SentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.tfidf_model = None\n",
        "        self.tfidf_vectorizer = None\n",
        "        self.w2v_model = None\n",
        "        self.w2v_classifier = None\n",
        "        self.is_trained = False  # Track if models are trained\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        \"\"\"Clean and preprocess text\"\"\"\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove special characters and digits\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        # Remove extra whitespace\n",
        "        text = ' '.join(text.split())\n",
        "        return text\n",
        "\n",
        "    def create_sample_data(self):\n",
        "        \"\"\"Create sample training data since no actual data is provided\"\"\"\n",
        "        print(\"Creating sample training data...\")\n",
        "\n",
        "        # Sample positive reviews\n",
        "        positive_reviews = [\n",
        "            \"This product is absolutely amazing! I love it.\",\n",
        "            \"Excellent quality and great value for money.\",\n",
        "            \"Highly recommended. Works perfectly as described.\",\n",
        "            \"Outstanding performance and durability.\",\n",
        "            \"Fantastic product with amazing features.\",\n",
        "            \"Very satisfied with this purchase.\",\n",
        "            \"Top notch quality and excellent customer service.\",\n",
        "            \"Impressive product that exceeded my expectations.\",\n",
        "            \"Wonderful experience using this product.\",\n",
        "            \"Great value and excellent performance.\"\n",
        "        ]\n",
        "\n",
        "        # Sample negative reviews\n",
        "        negative_reviews = [\n",
        "            \"Terrible product. Complete waste of money.\",\n",
        "            \"Poor quality and does not work as advertised.\",\n",
        "            \"Very disappointed with this purchase.\",\n",
        "            \"Stopped working after just a few days.\",\n",
        "            \"Low quality materials and bad craftsmanship.\",\n",
        "            \"Not worth the price at all.\",\n",
        "            \"Defective product, would not recommend.\",\n",
        "            \"Extremely dissatisfied with this item.\",\n",
        "            \"Cheaply made and broke quickly.\",\n",
        "            \"Worst purchase I've made in a long time.\"\n",
        "        ]\n",
        "\n",
        "        # Sample neutral reviews\n",
        "        neutral_reviews = [\n",
        "            \"It's okay, nothing special but gets the job done.\",\n",
        "            \"Average product with average performance.\",\n",
        "            \"Not great but not terrible either.\",\n",
        "            \"Mediocre quality for the price.\",\n",
        "            \"Does what it's supposed to but nothing more.\",\n",
        "            \"Acceptable but I expected better.\",\n",
        "            \"Fair product for the price point.\",\n",
        "            \"Neither impressed nor disappointed.\",\n",
        "            \"It works but there are better options.\",\n",
        "            \"Adequate but not exceptional in any way.\"\n",
        "        ]\n",
        "\n",
        "        # Combine all reviews and create labels\n",
        "        reviews = positive_reviews + negative_reviews + neutral_reviews\n",
        "        labels = ([\"positive\"] * len(positive_reviews) +\n",
        "                 [\"negative\"] * len(negative_reviews) +\n",
        "                 [\"neutral\"] * len(neutral_reviews))\n",
        "\n",
        "        return reviews, labels\n",
        "\n",
        "    def train_models(self):\n",
        "        \"\"\"Train both TF-IDF and Word2Vec models with sample data\"\"\"\n",
        "        print(\"Training models with sample data...\")\n",
        "\n",
        "        # Create sample data\n",
        "        X_train, y_train = self.create_sample_data()\n",
        "\n",
        "        # TF-IDF Model\n",
        "        self.tfidf_vectorizer = TfidfVectorizer(\n",
        "            max_features=5000,\n",
        "            ngram_range=(1, 2),\n",
        "            min_df=1,  # Changed to 1 for small sample data\n",
        "            max_df=0.95,  # Adjusted for small sample data\n",
        "            stop_words='english'\n",
        "        )\n",
        "\n",
        "        X_train_tfidf = self.tfidf_vectorizer.fit_transform(X_train)\n",
        "        self.tfidf_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "        self.tfidf_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "        print(\"Training Word2Vec model...\")\n",
        "        # Word2Vec Model\n",
        "        train_tokens = [simple_preprocess(text, deacc=True) for text in X_train]\n",
        "        self.w2v_model = Word2Vec(\n",
        "            sentences=train_tokens,\n",
        "            vector_size=100,\n",
        "            window=5,\n",
        "            min_count=1,  # Changed to 1 for small sample data\n",
        "            workers=4,\n",
        "            sg=0,  # CBOW\n",
        "            epochs=10\n",
        "        )\n",
        "\n",
        "        # Convert to vectors\n",
        "        X_train_w2v = np.array([self._review_to_vector(tokens) for tokens in train_tokens])\n",
        "        self.w2v_classifier = LogisticRegression(random_state=42, max_iter=1000)\n",
        "        self.w2v_classifier.fit(X_train_w2v, y_train)\n",
        "\n",
        "        self.is_trained = True\n",
        "        print(\"Models trained successfully!\")\n",
        "\n",
        "    def _review_to_vector(self, tokens):\n",
        "        \"\"\"Convert tokenized review to Word2Vec vector\"\"\"\n",
        "        if not self.w2v_model:\n",
        "            return np.zeros(100)  # Return zero vector if model not trained\n",
        "\n",
        "        word_vectors = [self.w2v_model.wv[word] for word in tokens\n",
        "                       if word in self.w2v_model.wv.key_to_index]\n",
        "\n",
        "        if len(word_vectors) == 0:\n",
        "            return np.zeros(self.w2v_model.wv.vector_size)\n",
        "        else:\n",
        "            return np.mean(word_vectors, axis=0)\n",
        "\n",
        "    def predict_tfidf(self, text):\n",
        "        \"\"\"Predict using TF-IDF model\"\"\"\n",
        "        if not self.is_trained:\n",
        "            return \"Model not trained\", {\"positive\": 0.33, \"negative\": 0.33, \"neutral\": 0.33}\n",
        "\n",
        "        processed_text = self.preprocess_text(text)\n",
        "        text_vector = self.tfidf_vectorizer.transform([processed_text])\n",
        "\n",
        "        # Get prediction and probabilities\n",
        "        prediction = self.tfidf_model.predict(text_vector)[0]\n",
        "        probabilities = self.tfidf_model.predict_proba(text_vector)[0]\n",
        "\n",
        "        # Get class names\n",
        "        classes = self.tfidf_model.classes_\n",
        "        prob_dict = {classes[i]: float(probabilities[i]) for i in range(len(classes))}\n",
        "\n",
        "        return prediction, prob_dict\n",
        "\n",
        "    def predict_word2vec(self, text):\n",
        "        \"\"\"Predict using Word2Vec model\"\"\"\n",
        "        if not self.is_trained:\n",
        "            return \"Model not trained\", {\"positive\": 0.33, \"negative\": 0.33, \"neutral\": 0.33}\n",
        "\n",
        "        processed_text = self.preprocess_text(text)\n",
        "        tokens = simple_preprocess(processed_text, deacc=True)\n",
        "        text_vector = self._review_to_vector(tokens).reshape(1, -1)\n",
        "\n",
        "        # Get prediction and probabilities\n",
        "        prediction = self.w2v_classifier.predict(text_vector)[0]\n",
        "        probabilities = self.w2v_classifier.predict_proba(text_vector)[0]\n",
        "\n",
        "        # Get class names\n",
        "        classes = self.w2v_classifier.classes_\n",
        "        prob_dict = {classes[i]: float(probabilities[i]) for i in range(len(classes))}\n",
        "\n",
        "        return prediction, prob_dict\n",
        "\n",
        "    def get_similar_words(self, word):\n",
        "        \"\"\"Get similar words using Word2Vec\"\"\"\n",
        "        if not self.is_trained:\n",
        "            return \"Model not trained yet. Please train the model first.\"\n",
        "\n",
        "        try:\n",
        "            if word.lower() in self.w2v_model.wv.key_to_index:\n",
        "                similar_words = self.w2v_model.wv.most_similar(word.lower(), topn=5)\n",
        "                return similar_words\n",
        "            else:\n",
        "                return f\"Word '{word}' not found in vocabulary\"\n",
        "        except:\n",
        "            return \"Error finding similar words\"\n",
        "\n",
        "# Initialize and train the analyzer\n",
        "analyzer = SentimentAnalyzer()\n",
        "analyzer.train_models()  # Train with sample data\n",
        "\n",
        "def analyze_sentiment(text, model_choice):\n",
        "    \"\"\"Main function for Gradio interface\"\"\"\n",
        "    if not text.strip():\n",
        "        return \"Please enter some text to analyze.\", {}, \"\"\n",
        "\n",
        "    try:\n",
        "        if model_choice == \"TF-IDF\":\n",
        "            prediction, probabilities = analyzer.predict_tfidf(text)\n",
        "            model_info = \"🔤 TF-IDF: Frequency-based word representation\"\n",
        "        else:  # Word2Vec\n",
        "            prediction, probabilities = analyzer.predict_word2vec(text)\n",
        "            model_info = \"🧠 Word2Vec: Semantic word embeddings (CS224N!)\"\n",
        "\n",
        "        return f\"**Prediction: {prediction}**\", probabilities, model_info\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", {}, \"\"\n",
        "\n",
        "def find_similar_words(word):\n",
        "    \"\"\"Find similar words using Word2Vec\"\"\"\n",
        "    try:\n",
        "        similar = analyzer.get_similar_words(word)\n",
        "        if isinstance(similar, str):\n",
        "            return similar\n",
        "        else:\n",
        "            result = f\"Words similar to '{word}':\\n\"\n",
        "            for word_sim, score in similar:\n",
        "                result += f\"• {word_sim} (similarity: {score:.3f})\\n\"\n",
        "            return result\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio Interface\n",
        "with gr.Blocks(title=\"Sentiment Analysis: TF-IDF vs Word2Vec\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"# 🎭 Sentiment Analysis Comparison\")\n",
        "    gr.Markdown(\"### TF-IDF vs Word2Vec Models (CS224N Implementation)\")\n",
        "\n",
        "    with gr.Tab(\"🔍 Sentiment Analysis\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=2):\n",
        "                text_input = gr.Textbox(\n",
        "                    label=\"Enter text to analyze:\",\n",
        "                    placeholder=\"This product is amazing! I love it.\",\n",
        "                    lines=3\n",
        "                )\n",
        "                model_choice = gr.Radio(\n",
        "                    choices=[\"TF-IDF\", \"Word2Vec\"],\n",
        "                    label=\"Choose Model:\",\n",
        "                    value=\"TF-IDF\"\n",
        "                )\n",
        "                analyze_btn = gr.Button(\"🔍 Analyze Sentiment\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                prediction_output = gr.Markdown(label=\"Prediction\")\n",
        "                probabilities_output = gr.Label(label=\"Confidence Scores\")\n",
        "                model_info = gr.Markdown(label=\"Model Info\")\n",
        "\n",
        "        # Example texts\n",
        "        gr.Markdown(\"### 📝 Try These Examples:\")\n",
        "        gr.Examples([\n",
        "            \"This product is absolutely terrible! Waste of money.\",\n",
        "            \"The item is okay, nothing special but works fine.\",\n",
        "            \"Amazing quality! Exceeded my expectations completely!\",\n",
        "            \"The service was poor and the product arrived damaged.\"\n",
        "        ], inputs=text_input)\n",
        "\n",
        "    with gr.Tab(\"🔤 Word2Vec Similar Words\"):\n",
        "        gr.Markdown(\"## Find Similar Words using Word2Vec\")\n",
        "        word_input = gr.Textbox(\n",
        "            label=\"Enter a word to find similar words:\",\n",
        "            placeholder=\"amazing\",\n",
        "            lines=1\n",
        "        )\n",
        "        similar_btn = gr.Button(\"Find Similar Words\", variant=\"primary\")\n",
        "        similar_output = gr.Textbox(label=\"Similar Words\", lines=6)\n",
        "\n",
        "        similar_btn.click(\n",
        "            fn=find_similar_words,\n",
        "            inputs=word_input,\n",
        "            outputs=similar_output\n",
        "        )\n",
        "\n",
        "    # Connect the analyze button\n",
        "    analyze_btn.click(\n",
        "        fn=analyze_sentiment,\n",
        "        inputs=[text_input, model_choice],\n",
        "        outputs=[prediction_output, probabilities_output, model_info]\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cC7d6LFwlxR",
        "outputId": "0ca25304-ca79-4055-e2b0-4a2ed9047f3d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training models with sample data...\n",
            "Creating sample training data...\n",
            "Training Word2Vec model...\n",
            "Models trained successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    demo.launch(share=True, inline=False)  # For Colab\n",
        "else:\n",
        "    demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWqXrvyDw7b0",
        "outputId": "2f913bfb-bde6-458b-8227-7fa34e5ae006"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4156cdf5cb81a73aaf.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        }
      ]
    }
  ]
}